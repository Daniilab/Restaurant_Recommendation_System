{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import lil_matrix, coo_matrix\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPPING user id and restaraunt id to index in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1143</th>\n",
       "      <th>1144</th>\n",
       "      <th>1145</th>\n",
       "      <th>1146</th>\n",
       "      <th>1147</th>\n",
       "      <th>1148</th>\n",
       "      <th>1149</th>\n",
       "      <th>1150</th>\n",
       "      <th>1151</th>\n",
       "      <th>1152</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6504</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6505</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6506</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6507</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6508</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6509 rows × 1153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  1143  \\\n",
       "0      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "1      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "2      NaN   NaN   NaN   NaN   NaN   NaN   5.0   NaN   NaN   NaN  ...   NaN   \n",
       "3      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "4      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   4.0   NaN  ...   NaN   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "6504   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "6505   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "6506   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "6507   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "6508   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "\n",
       "      1144  1145  1146  1147  1148  1149  1150  1151  1152  \n",
       "0      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "6504   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "6505   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "6506   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "6507   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "6508   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[6509 rows x 1153 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_data = pd.read_csv('../data/UI_matrix_n_5_r.csv')\n",
    "\n",
    "all_data = all_data.set_index('user_id')\n",
    "\n",
    "user_index_to_id = {index: user_id for index, user_id in enumerate(all_data.index)}\n",
    "user_id_to_index = {user_id: index for index, user_id in user_index_to_id.items()}\n",
    "\n",
    "#user_index_to_id[0] would return the first user id\n",
    "#user_id_to_index[\"-1-ECBsGpG4Iw5s-ecnfqw\"] would return 0\n",
    "\n",
    "item_index_to_id = {index: business_id for index, business_id in enumerate(all_data.columns)}\n",
    "item_id_to_index = {business_id: index for index, business_id in item_index_to_id.items()}\n",
    "\n",
    "all_data.rename(columns=item_id_to_index, inplace=True)\n",
    "\n",
    "# Map each user_id in the index to its corresponding index number\n",
    "new_index = all_data.index.map(user_id_to_index)\n",
    "\n",
    "# Set this new index to the DataFrame\n",
    "all_data.set_index(new_index, inplace=True)\n",
    "\n",
    "all_data.index.name = None\n",
    "\n",
    "\n",
    "all_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPPING resturaunt name to id and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1153"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/yelp_dataset/yelp_academic_dataset_business.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        data_business = [json.loads (line) for line in file]\n",
    "\n",
    "df_business = pd.DataFrame(data_business)\n",
    "\n",
    "user_item_matrix = pd.read_csv('../data/UI_matrix_n_5_r.csv')\n",
    "\n",
    "\n",
    "# Assuming the first column in user_item_matrix is not a business ID, we exclude it\n",
    "business_ids = user_item_matrix.columns[1:]\n",
    "\n",
    "# Filter df_business to keep only rows where business_id is in the list of business_ids\n",
    "filtered_df_business = df_business[df_business['business_id'].isin(business_ids)]\n",
    "\n",
    "id_to_restaurant = filtered_df_business.set_index('business_id')['name'].to_dict()\n",
    "\n",
    "restaurant_to_id = {value: key for key, value in id_to_restaurant.items()}\n",
    "\n",
    "\n",
    "len(restaurant_to_id)\n",
    "len(id_to_restaurant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain model on all data given best hyper paramters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepping dataset for matrix factorization\n",
    "all_data.fillna(0, inplace=True)\n",
    "\n",
    "all_data_sparse = coo_matrix(all_data.to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def matrix_factorization_SGD(R, K, alpha, beta, iterations):\n",
    "\n",
    "    np.random.seed(42)  \n",
    "    \n",
    "    num_users, num_items = R.shape\n",
    "    P = np.random.rand(num_users, K)\n",
    "    Q = np.random.rand(num_items, K)\n",
    "\n",
    "    R_coo = coo_matrix(R)\n",
    "    non_zero_ratings = list(zip(R_coo.row, R_coo.col, R_coo.data))\n",
    "\n",
    "    for it in range(iterations):\n",
    "        np.random.shuffle(non_zero_ratings)\n",
    "        for user_idx, item_idx, r in non_zero_ratings:\n",
    "            prediction = np.dot(P[user_idx, :], Q[item_idx, :].T)\n",
    "            e = r - prediction\n",
    "            P[user_idx, :] += alpha * (e * Q[item_idx, :] - beta * P[user_idx, :])\n",
    "            Q[item_idx, :] += alpha * (e * P[user_idx, :] - beta * Q[item_idx, :])\n",
    "\n",
    "    return P, Q.T\n",
    "\n",
    "\n",
    "#these hyperparameters were identified as ideal via bayesion optimization in script 3\n",
    "K = 18\n",
    "alpha = 0.005273041694145949\n",
    "beta = 0.18189763744227455\n",
    "iterations = 4\n",
    "\n",
    "\n",
    "P, Q = matrix_factorization_SGD(all_data_sparse, K, alpha, beta, iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# definition function to convert restaurants to ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_liked_business_ids(liked_restaurants):\n",
    "\n",
    "\n",
    "    liked_business_ids = []\n",
    "    for restaurant_name in liked_restaurants:\n",
    "        if restaurant_name in restaurant_to_id:\n",
    "            liked_business_ids.append(restaurant_to_id[restaurant_name])\n",
    "        else:\n",
    "            print(f\"Restaurant '{restaurant_name}' not found in the dataset.\")\n",
    "\n",
    "    return liked_business_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generating a user_ratings vector based on the user's liked restaraunts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_ratings_vector(liked_restaurants):\n",
    "\n",
    "\n",
    "    # Initialize the user ratings vector with NaNs\n",
    "    user_ratings = pd.Series(np.nan, index=user_item_matrix.columns[1:])\n",
    "\n",
    "    liked_business_ids = get_liked_business_ids(liked_restaurants)\n",
    "\n",
    "\n",
    "    # Set ratings for liked businesses\n",
    "    for business_id in liked_business_ids:\n",
    "        if business_id in user_ratings.index:\n",
    "            user_ratings[business_id] = 5  # Set the rating as 5 for liked businesses\n",
    "\n",
    "\n",
    "    user_ratings_df = user_ratings.to_frame(name='rating')\n",
    "\n",
    "    user_ratings_df_T = user_ratings_df.T\n",
    "\n",
    "    return  user_ratings_df_T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generating latent feature vector for new user\n",
    "\n",
    "\n",
    "    Infers the latent features for a new user based on their ratings.\n",
    "\n",
    "    Parameters:\n",
    "    user_ratings (DataFrame): The ratings given by the new user, NaN for unrated items.\n",
    "    item_features (array): The item feature matrix (Q) from matrix factorization.\n",
    "    learning_rate (float): The learning rate for SGD.\n",
    "    iterations (int): Number of iterations for the optimization process.\n",
    "\n",
    "    Returns:\n",
    "    array: The inferred latent features of the new user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def infer_new_user_features(liked_restaurants, item_features = Q, learning_rate=0.01, iterations=100):\n",
    "\n",
    "\n",
    "    user_ratings = get_user_ratings_vector(liked_restaurants)\n",
    "\n",
    "    num_features = item_features.shape[0]  # Number of latent features\n",
    "    user_features = np.random.rand(num_features)  # Randomly initialize user features\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        for i in range(item_features.shape[1]):  # Iterate through items\n",
    "            rating = user_ratings.iloc[0, i]  # Access the rating using .iloc for DataFrame\n",
    "            if not np.isnan(rating):  # Only consider rated items\n",
    "                error = rating - np.dot(user_features, item_features[:, i])\n",
    "                user_features += learning_rate * (error * item_features[:, i] - 0.02 * user_features)  # Regularization\n",
    "\n",
    "    return user_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing hybrid model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hybrid_reccomendations(keyword, liked_restaurants, n):\n",
    "\n",
    "    new_user_features = infer_new_user_features(liked_restaurants)\n",
    "\n",
    "    predicted_ratings = np.dot(new_user_features, Q)\n",
    "\n",
    "    # Sorting the predicted ratings in descending order and obtaining the indices. This is a list of indicies of top reccomendations in item feature matrix (Q). The first 10 elements are the top 10 reccomendations \n",
    "    restaurant_indices_sorted  = np.argsort(predicted_ratings)[::-1]   \n",
    "\n",
    "    #converting reccomended restaraunt indices to restaraunt ids\n",
    "    recommended_business_ids = [item_index_to_id[idx] for idx in restaurant_indices_sorted]\n",
    "\n",
    "\n",
    "    desired_atmosphere = keyword\n",
    "\n",
    "    # Open the JSON file for reading\n",
    "    with open('../data/keywords_restaurants.json', 'r') as file:\n",
    "    # Parse the JSON file and convert it into a Python dictionary\n",
    "        keyword_to_restaurant_ids = json.load(file)\n",
    "\n",
    "\n",
    "    #Filtering for restaurants in the dataset that contain that keyword\n",
    "    suitable_restaurants = keyword_to_restaurant_ids[desired_atmosphere]\n",
    "\n",
    "    \n",
    "    # Filtering recommended_business_ids to include only those that contain the keyword\n",
    "    filtered_recommendations = [id for id in recommended_business_ids if id in suitable_restaurants]\n",
    "\n",
    "    #converting reccomended restaraunt ids to names\n",
    "    recommended_business_names = [id_to_restaurant[idx] for idx in filtered_recommendations]\n",
    "\n",
    "    # getting the top n reccomendations only \n",
    "    top_n_recommended_business_names = recommended_business_names[:n]\n",
    "\n",
    "\n",
    "    return top_n_recommended_business_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reccomendations! Input known liked restaurants in the Santa Barbara Area, run the cell, and input desired atmosphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant 'Lily's Taco' not found in the dataset.\n",
      "Restaurant 'Habit Burger' not found in the dataset.\n",
      "Restaurant 'Thario’s' not found in the dataset.\n",
      "----------------------------\n",
      "Here are some cozy restaurants that you will enjoy: [\"Rascal's Vegan Food\", 'Ty Lounge', 'Apero', 'Events By Rincon', 'The Set', 'Lucca Truck', 'Restaurant Mimosa', 'Alessia Patisserie & Cafe ', 'Le Café', 'Aperitivo']\n"
     ]
    }
   ],
   "source": [
    "# Example: User inputs\n",
    "liked_restaurants = [\"Lily's Taco\", \"Himalayan Kitchen\", \"Freebirds\", \"Barbareño\", \"Habit Burger\", \"Padaro Beach Grill\", \"Thario’s\",\"Tre Lune\"]\n",
    "\n",
    "#Example: User inputs:\n",
    "desired_atmosphere = input(\"What is your desired atmosphere? Type in one of the following: romantic, intimate,  anniversary, birthday, friends, unique, celebration, live music, outdoor seating, upscale, rooftop, waterfront, scenic, hidden gem, cozy, affordable, fine-dining, dimly lit \")\n",
    "\n",
    "reccomendations = hybrid_reccomendations(desired_atmosphere, liked_restaurants, 10)\n",
    "\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(f\"Here are some {desired_atmosphere} restaurants that you will enjoy: {reccomendations}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
