{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import lil_matrix, coo_matrix\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPPING user id and restaraunt id to index in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1143</th>\n",
       "      <th>1144</th>\n",
       "      <th>1145</th>\n",
       "      <th>1146</th>\n",
       "      <th>1147</th>\n",
       "      <th>1148</th>\n",
       "      <th>1149</th>\n",
       "      <th>1150</th>\n",
       "      <th>1151</th>\n",
       "      <th>1152</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6504</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6505</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6506</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6507</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6508</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6509 rows × 1153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  1143  \\\n",
       "0      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "1      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "2      NaN   NaN   NaN   NaN   NaN   NaN   5.0   NaN   NaN   NaN  ...   NaN   \n",
       "3      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "4      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   4.0   NaN  ...   NaN   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "6504   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "6505   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "6506   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "6507   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "6508   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "\n",
       "      1144  1145  1146  1147  1148  1149  1150  1151  1152  \n",
       "0      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "6504   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "6505   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "6506   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "6507   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "6508   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[6509 rows x 1153 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_data = pd.read_csv('../data/UI_matrix_n_5_r.csv')\n",
    "\n",
    "all_data = all_data.set_index('user_id')\n",
    "\n",
    "user_index_to_id = {index: user_id for index, user_id in enumerate(all_data.index)}\n",
    "user_id_to_index = {user_id: index for index, user_id in user_index_to_id.items()}\n",
    "\n",
    "#user_index_to_id[0] would return the first user id\n",
    "#user_id_to_index[\"-1-ECBsGpG4Iw5s-ecnfqw\"] would return 0\n",
    "\n",
    "item_index_to_id = {index: business_id for index, business_id in enumerate(all_data.columns)}\n",
    "item_id_to_index = {business_id: index for index, business_id in item_index_to_id.items()}\n",
    "\n",
    "all_data.rename(columns=item_id_to_index, inplace=True)\n",
    "\n",
    "# Map each user_id in the index to its corresponding index number\n",
    "new_index = all_data.index.map(user_id_to_index)\n",
    "\n",
    "# Set this new index to the DataFrame\n",
    "all_data.set_index(new_index, inplace=True)\n",
    "\n",
    "all_data.index.name = None\n",
    "\n",
    "\n",
    "all_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPPING resturaunt name to id and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1153"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/yelp_dataset/yelp_academic_dataset_business.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        data_business = [json.loads (line) for line in file]\n",
    "\n",
    "df_business = pd.DataFrame(data_business)\n",
    "\n",
    "user_item_matrix = pd.read_csv('../data/UI_matrix_n_5_r.csv')\n",
    "\n",
    "\n",
    "# Assuming the first column in user_item_matrix is not a business ID, we exclude it\n",
    "business_ids = user_item_matrix.columns[1:]\n",
    "\n",
    "# Filter df_business to keep only rows where business_id is in the list of business_ids\n",
    "filtered_df_business = df_business[df_business['business_id'].isin(business_ids)]\n",
    "\n",
    "id_to_restaurant = filtered_df_business.set_index('business_id')['name'].to_dict()\n",
    "\n",
    "restaurant_to_id = {value: key for key, value in id_to_restaurant.items()}\n",
    "\n",
    "\n",
    "len(restaurant_to_id)\n",
    "len(id_to_restaurant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain model on all data given best hyper paramters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv('../data/train_data_n5_r.csv')\n",
    "\n",
    "# test_data  = pd.read_csv('../data/test_data_n5_r.csv')\n",
    "\n",
    "\n",
    "# # Replace NaN values with zeros\n",
    "# train_data.fillna(0, inplace=True)\n",
    "# test_data.fillna(0, inplace=True)\n",
    "\n",
    "all_data.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# #creating a sparse representation of training / testing data\n",
    "# train_data_sparse = coo_matrix(train_data.to_numpy())\n",
    "\n",
    "# test_data_sparse = coo_matrix(test_data.to_numpy())\n",
    "\n",
    "all_data_sparse = coo_matrix(all_data.to_numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def matrix_factorization_SGD(R, K, alpha, beta, iterations):\n",
    "\n",
    "    np.random.seed(42)  \n",
    "    \n",
    "    num_users, num_items = R.shape\n",
    "    P = np.random.rand(num_users, K)\n",
    "    Q = np.random.rand(num_items, K)\n",
    "\n",
    "    R_coo = coo_matrix(R)\n",
    "    non_zero_ratings = list(zip(R_coo.row, R_coo.col, R_coo.data))\n",
    "\n",
    "    for it in range(iterations):\n",
    "        np.random.shuffle(non_zero_ratings)\n",
    "        for user_idx, item_idx, r in non_zero_ratings:\n",
    "            prediction = np.dot(P[user_idx, :], Q[item_idx, :].T)\n",
    "            e = r - prediction\n",
    "            P[user_idx, :] += alpha * (e * Q[item_idx, :] - beta * P[user_idx, :])\n",
    "            Q[item_idx, :] += alpha * (e * P[user_idx, :] - beta * Q[item_idx, :])\n",
    "\n",
    "    return P, Q.T\n",
    "\n",
    "# # Assuming R_train is your training matrix and is in sparse format\n",
    "# K = 12  # Number of latent factors\n",
    "# alpha = 0.001403450260491775\n",
    "# beta= 0.05933345569703825\n",
    "# iterations = 43\n",
    "\n",
    "K = 18\n",
    "alpha = 0.005273041694145949\n",
    "beta = 0.18189763744227455\n",
    "iterations = 4\n",
    "\n",
    "\n",
    "\n",
    "P, Q = matrix_factorization_SGD(all_data_sparse, K, alpha, beta, iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User inputs known liked restaurants below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: User inputs\n",
    "liked_restaurants = [\"Lily's Taco\", \"Himalayan Kitchen\", \"Freebirds\", \"Barbareño\", \"Habit Burger\", \"Padaro Beach Grill\", \"Thario’s\",\"Tre Lune\"]\n",
    "\n",
    "#input desired atmoshpere. options = [\"romantic\", \"intimate\", \"date\", \"birthday\", \"friends\", \"date-night\", \"anniversary\", \"unique\", \"celebration\", \"music\"]\n",
    "\n",
    "#Example: User inputs:\n",
    "desired_atmosphere = [\"romantic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant 'Lily's Taco' not found in the dataset.\n",
      "Restaurant 'Habit Burger' not found in the dataset.\n",
      "Restaurant 'Thario’s' not found in the dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['BwUWmUFKCuJ-nN9vFwMt2Q',\n",
       " 'Rl42JbSMsmNW3LRjsTMYAg',\n",
       " '6HTGlttrzCMsuGBHO1ZGiw',\n",
       " '1FURjeGJi_LBXcJQg8eskw',\n",
       " 'S3QHy1sshUeZwXOYviVsXQ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "liked_business_ids = []\n",
    "for restaurant_name in liked_restaurants:\n",
    "    if restaurant_name in restaurant_to_id:\n",
    "        liked_business_ids.append(restaurant_to_id[restaurant_name])\n",
    "    else:\n",
    "        print(f\"Restaurant '{restaurant_name}' not found in the dataset.\")\n",
    "\n",
    "\n",
    "liked_business_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generating a user_ratings vector based on the user's liked restaraunts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the user ratings vector with NaNs\n",
    "user_ratings = pd.Series(np.nan, index=user_item_matrix.columns[1:])\n",
    "\n",
    "# Set ratings for liked businesses\n",
    "for business_id in liked_business_ids:\n",
    "    if business_id in user_ratings.index:\n",
    "        user_ratings[business_id] = 5  # Set the rating as 5 for liked businesses\n",
    "\n",
    "\n",
    "user_ratings_df = user_ratings.to_frame(name='rating')\n",
    "\n",
    "user_ratings_df_T = user_ratings_df.T\n",
    "\n",
    "# # Check ratings in the DataFrame\n",
    "# for business_id in liked_business_ids:\n",
    "#     print(f\"Rating for {business_id} in DataFrame: {user_ratings_df.loc[business_id, 'rating']}\")\n",
    "\n",
    "\n",
    "# len(user_ratings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generating latent feature vector for new user\n",
    "\n",
    "\n",
    "    Infers the latent features for a new user based on their ratings.\n",
    "\n",
    "    Parameters:\n",
    "    user_ratings (DataFrame): The ratings given by the new user, NaN for unrated items.\n",
    "    item_features (array): The item feature matrix (Q) from matrix factorization.\n",
    "    learning_rate (float): The learning rate for SGD.\n",
    "    iterations (int): Number of iterations for the optimization process.\n",
    "\n",
    "    Returns:\n",
    "    array: The inferred latent features of the new user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def infer_new_user_features(user_ratings, item_features, learning_rate=0.01, iterations=100):\n",
    "    \n",
    "    num_features = item_features.shape[0]  # Number of latent features\n",
    "    user_features = np.random.rand(num_features)  # Randomly initialize user features\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        for i in range(item_features.shape[1]):  # Iterate through items\n",
    "            rating = user_ratings.iloc[0, i]  # Access the rating using .iloc for DataFrame\n",
    "            if not np.isnan(rating):  # Only consider rated items\n",
    "                error = rating - np.dot(user_features, item_features[:, i])\n",
    "                user_features += learning_rate * (error * item_features[:, i] - 0.02 * user_features)  # Regularization\n",
    "\n",
    "    return user_features\n",
    "\n",
    "\n",
    "new_user_features = infer_new_user_features(user_ratings_df_T, Q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting ratings\n",
    "\n",
    "    Predict ratings for each item based on the user's features.\n",
    "\n",
    "    Parameters:\n",
    "    user_features (array): The inferred latent features of the user.\n",
    "    item_features (array): The item feature matrix (Q) from matrix factorization.\n",
    "\n",
    "    Returns:\n",
    "    array: Predicted ratings for each item.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings(user_features, item_features):\n",
    "\n",
    "    predicted_ratings = np.dot(user_features, item_features)\n",
    "    return predicted_ratings #essentially returns a nwe row in a user_item matrix with predicted ratings for every restaraunt  \n",
    "\n",
    "\n",
    "def reccomended_restaraunts(n):\n",
    "\n",
    "    # Predict ratings for all restaurants\n",
    "    predicted_ratings = predict_ratings(new_user_features, Q)\n",
    "\n",
    "    # Get the indices (restaurant IDs) of the top N predictions\n",
    "    top_n_recommendations = np.argsort(predicted_ratings)[::-1][:n]   #represents the indices of the restaurants in item feature matrix (Q) that are the top recommendations for the user.\n",
    "    # 'top_n_recommendations' is your list of top indices from the recommendation model\n",
    "\n",
    "    #converting reccomended restaraunt indices to restaraunt ids\n",
    "    recommended_business_ids = [item_index_to_id[idx] for idx in top_n_recommendations]\n",
    "\n",
    "    #converting reccomended restaraunt ids to names\n",
    "    recommended_business_names = [id_to_restaurant[idx] for idx in recommended_business_ids]\n",
    "\n",
    "    return recommended_business_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Carrillo Dining Commons',\n",
       " \"Maudet's\",\n",
       " 'European Deli',\n",
       " 'Palihouse Santa Barbara',\n",
       " 'Baba Small Batch',\n",
       " 'The Mill',\n",
       " 'Red Pepper Chinese Food Express',\n",
       " 'The Beach Grill at Padaro',\n",
       " \"L's Kitchen\",\n",
       " 'Le Bon Cafe']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reccomended_restaraunts(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing hybrid model -- Note: Code below was used as a rough draft. See script 6 for final version of hybrid model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Book Ends Cafe', \"Yoichi's\", 'Barbareño', 'Modern Times Academy of Recreational Sciences', 'Finch & Fork', 'Oku', 'The Ritz-Carlton Bacara, Santa Barbara', 'The Honey B', 'Crushcakes & Cafe', 'Stearns Wharf']\n"
     ]
    }
   ],
   "source": [
    "def predict_ratings(user_features, item_features):\n",
    "\n",
    "    predicted_ratings = np.dot(user_features, item_features)\n",
    "    return predicted_ratings #essentially returns a nwe row in a user_item matrix with predicted ratings for every restaraunt  \n",
    "\n",
    "\n",
    "\n",
    "def hybrid_reccomendations(keyword, n):\n",
    "    desired_atmosphere = keyword\n",
    "\n",
    "    # Open the JSON file for reading\n",
    "    with open('../data/keywords_restaurants.json', 'r') as file:\n",
    "    # Parse the JSON file and convert it into a Python dictionary\n",
    "        keyword_to_restaurant_ids = json.load(file)\n",
    "\n",
    "    #Filtering for restaurants in the dataset that contain that keyword\n",
    "    suitable_restaurants = keyword_to_restaurant_ids[desired_atmosphere]\n",
    "\n",
    "\n",
    "    #Predict Scores for All Restaurants from matrix factorization model\n",
    "    predicted_ratings = predict_ratings(new_user_features, Q)\n",
    "\n",
    "\n",
    "    # Sorting the predicted ratings in descending order and obtaining the indices. This is a list of indicies of top reccomendations in item feature matrix (Q). The first 10 elements are the top 10 reccomendations \n",
    "    restaurant_indices_sorted  = np.argsort(predicted_ratings)[::-1]   \n",
    "\n",
    "    #converting reccomended restaraunt indices to restaraunt ids\n",
    "    recommended_business_ids = [item_index_to_id[idx] for idx in restaurant_indices_sorted]\n",
    "\n",
    "    # Filtering recommended_business_ids to include only those that contain the keyword\n",
    "    filtered_recommendations = [id for id in recommended_business_ids if id in suitable_restaurants]\n",
    "\n",
    "    #converting reccomended restaraunt ids to names\n",
    "    recommended_business_names = [id_to_restaurant[idx] for idx in filtered_recommendations]\n",
    "\n",
    "    # getting the top n reccomendations only \n",
    "    top_n_recommended_business_names = recommended_business_names[:n]\n",
    "\n",
    "\n",
    "    return top_n_recommended_business_names\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(hybrid_reccomendations('rooftop', 10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Khao Kaeng by Empty Bowl Gourmet Noodle Bar', 'Sevilla', 'University Club of Santa Barbara', 'OPPI’Z Bistro And Natural Pizza', \"Downey's\", 'Bar 29', 'The Revere Room', \"Ruth's Chris Steak House\", 'Tydes Restaurant', 'Intermezzo By Wine Cask']\n"
     ]
    }
   ],
   "source": [
    "# Example: User inputs\n",
    "liked_restaurants = [\"Lily's Taco\", \"Himalayan Kitchen\", \"Freebirds\", \"Barbareño\", \"Habit Burger\", \"Padaro Beach Grill\", \"Thario’s\",\"Tre Lune\"]\n",
    "\n",
    "\n",
    "#Example: User inputs:\n",
    "desired_atmosphere = \"romantic\"\n",
    "#options = [\"romantic\", \"intimate\", \"date\", \"birthday\", \"friends\", \"date-night\", \"anniversary\", \"unique\", \"celebration\", \"music\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(hybrid_reccomendations(desired_atmosphere, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying reccomendations worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aYMpjij5ShtEoZueMrQPRw']\n"
     ]
    }
   ],
   "source": [
    "def predict_ratings(user_features, item_features):\n",
    "\n",
    "    predicted_ratings = np.dot(user_features, item_features)\n",
    "    return predicted_ratings #essentially returns a nwe row in a user_item matrix with predicted ratings for every restaraunt  \n",
    "\n",
    "\n",
    "\n",
    "def hybrid_reccomendations(keyword, n):\n",
    "    desired_atmosphere = keyword\n",
    "\n",
    "\n",
    "    # Open the JSON file for reading\n",
    "    with open('../data/keywords_restaurants.json', 'r') as file:\n",
    "    # Parse the JSON file and convert it into a Python dictionary\n",
    "        keyword_to_restaurant_ids = json.load(file)\n",
    "\n",
    "    #Filtering for restaurants in the dataset that contain that keyword\n",
    "    suitable_restaurants = keyword_to_restaurant_ids[desired_atmosphere]\n",
    "\n",
    "\n",
    "    #Predict Scores for All Restaurants from matrix factorization model\n",
    "    predicted_ratings = predict_ratings(new_user_features, Q)\n",
    "\n",
    "\n",
    "    # Sorting the predicted ratings in descending order and obtaining the indices. This is a list of indicies of top reccomendations in item feature matrix (Q). The first 10 elements are the top 10 reccomendations \n",
    "    restaurant_indices_sorted  = np.argsort(predicted_ratings)[::-1]   \n",
    "\n",
    "    #converting reccomended restaraunt indices to restaraunt ids\n",
    "    recommended_business_ids = [item_index_to_id[idx] for idx in restaurant_indices_sorted]\n",
    "\n",
    "    # Filtering recommended_business_ids to include only those that contain the keyword\n",
    "    filtered_recommendations = [id for id in recommended_business_ids if id in suitable_restaurants]\n",
    "\n",
    "\n",
    "\n",
    "    # getting the top n reccomendations only \n",
    "    top_n_recommended_business_names = filtered_recommendations[:n]\n",
    "\n",
    "\n",
    "    return top_n_recommended_business_names\n",
    "\n",
    "\n",
    "\n",
    "print(hybrid_reccomendations('live music', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Open the JSON file for reading\n",
    "with open('../data/keywords_restaurants.json', 'r') as file:\n",
    "# Parse the JSON file and convert it into a Python dictionary\n",
    "    keyword_to_restaurant_ids = json.load(file)\n",
    "\n",
    "\n",
    "# Assuming your dictionary is named keyword_to_restaurant_ids\n",
    "keyword = 'live music'\n",
    "restaurant_id = 'aYMpjij5ShtEoZueMrQPRw'\n",
    "\n",
    "# Check if the restaurant ID is in the list of IDs for the specified keyword\n",
    "is_in_romantic = restaurant_id in keyword_to_restaurant_ids.get(keyword, [])\n",
    "\n",
    "print(is_in_romantic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this was a quick test to verify that the reccomended businesses was associated with the requested keyword"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
